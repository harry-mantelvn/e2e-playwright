name: E2E Test Automation

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Test Environment"
        required: true
        default: "test"
        type: choice
        options:
          - test
          - prerelease
      test_scope:
        description: "Test Scope"
        required: true
        default: "all"
        type: choice
        options:
          - all
          - smoke
          - regression
          - basic
          - specific
      specific_spec:
        description: 'Specific Test File (when scope is "specific")'
        required: false
        default: "tests/basic.spec.ts"
        type: choice
        options:
          - tests/basic.spec.ts
          - tests/smoke/smoke-home.spec.ts
          - tests/smoke/smoke-auth.spec.ts
          - tests/smoke/smoke-cart.spec.ts
          - tests/regression/auth/register-login-logout.spec.ts
          - tests/regression/products/add-to-cart-and-checkout.spec.ts
          - tests/regression/contact/submit-contact-form.spec.ts
      workers:
        description: "Number of Workers"
        required: true
        default: "3"
        type: string
      email_recipients:
        description: "Email Recipients (comma-separated, optional)"
        required: false
        type: string
  push:
    branches: [main, develop]
    paths:
      - "automationexercise-e2e-pom/**"
  pull_request:
    branches: [main]
    paths:
      - "automationexercise-e2e-pom/**"
  schedule:
    # Run smoke tests daily at 6 AM UTC
    - cron: "0 6 * * *"

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "18"
          cache: "npm"
          cache-dependency-path: automationexercise-e2e-pom/package-lock.json

      - name: Install dependencies
        run: |
          cd automationexercise-e2e-pom
          npm ci

      - name: Install Playwright browsers
        run: |
          cd automationexercise-e2e-pom
          npx playwright install --with-deps

      - name: Run all tests
        if: ${{ github.event.inputs.test_scope == 'all' }}
        run: |
          cd automationexercise-e2e-pom
          npx cross-env NODE_ENV=${{ github.event.inputs.environment || 'test' }} npx playwright test --workers=${{ github.event.inputs.workers || '3' }}
        continue-on-error: true

      - name: Run smoke tests
        if: ${{ github.event.inputs.test_scope == 'smoke' || github.event_name == 'schedule' }}
        run: |
          cd automationexercise-e2e-pom
          npx cross-env NODE_ENV=${{ github.event.inputs.environment || 'test' }} npx playwright test tests/smoke --workers=${{ github.event.inputs.workers || '3' }}
        continue-on-error: true

      - name: Run regression tests
        if: ${{ github.event.inputs.test_scope == 'regression' }}
        run: |
          cd automationexercise-e2e-pom
          npx cross-env NODE_ENV=${{ github.event.inputs.environment || 'test' }} npx playwright test tests/regression --workers=${{ github.event.inputs.workers || '3' }}
        continue-on-error: true

      - name: Run basic test
        if: ${{ github.event.inputs.test_scope == 'basic' }}
        run: |
          cd automationexercise-e2e-pom
          npx cross-env NODE_ENV=${{ github.event.inputs.environment || 'test' }} npx playwright test tests/basic.spec.ts --workers=${{ github.event.inputs.workers || '3' }}
        continue-on-error: true

      - name: Run specific test
        if: ${{ github.event.inputs.test_scope == 'specific' }}
        run: |
          cd automationexercise-e2e-pom
          npx cross-env NODE_ENV=${{ github.event.inputs.environment || 'test' }} npx playwright test ${{ github.event.inputs.specific_spec }} --workers=${{ github.event.inputs.workers || '3' }}
        continue-on-error: true

      - name: Run automatic tests on push/PR
        if: ${{ github.event_name == 'push' || github.event_name == 'pull_request' }}
        run: |
          cd automationexercise-e2e-pom
          npx cross-env NODE_ENV=test npx playwright test tests/smoke --workers=3
        continue-on-error: true

      - name: Generate Allure Report
        if: always()
        run: |
          cd automationexercise-e2e-pom
          npm run allure:generate || echo "Allure report generation failed, continuing..."
        continue-on-error: true

      - name: Generate Test Metrics and Enhanced Email Report
        if: always()
        run: |
          cd automationexercise-e2e-pom
          npm run metrics:generate || echo "Metrics generation failed, continuing..."
          npm run email:enhanced || echo "Enhanced email report generation failed, continuing..."
          npm run email:generate || echo "Basic email report generation failed, continuing..."
        continue-on-error: true

      - name: Upload Allure Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: allure-report-${{ github.event.inputs.environment || 'test' }}-${{ github.run_number }}
          path: automationexercise-e2e-pom/single-file-reports/
          retention-days: 30

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.event.inputs.environment || 'test' }}-${{ github.run_number }}
          path: |
            automationexercise-e2e-pom/test-results/
            automationexercise-e2e-pom/test-reports/
          retention-days: 30

      - name: Upload Playwright Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ github.run_number }}
          path: automationexercise-e2e-pom/playwright-report/
          retention-days: 30

      - name: Upload Enhanced Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: enhanced-reports-${{ github.run_number }}
          path: |
            automationexercise-e2e-pom/test-summary/
          retention-days: 30

      - name: Generate Enhanced Test Summary
        if: always()
        run: |
          cd automationexercise-e2e-pom

          # Read metrics if available
          if [ -f "test-summary/metrics.json" ]; then
            TOTAL_TESTS=$(grep '"total_tests"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            TOTAL_TEST_CASES=$(grep '"total_test_cases"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            PASSED_TESTS=$(grep '"passed_tests"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            FAILED_TESTS=$(grep '"failed_tests"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            PASS_RATE=$(grep '"pass_rate"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            TEST_COVERAGE=$(grep '"test_coverage_percentage"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "85")
          else
            TOTAL_TESTS=0; TOTAL_TEST_CASES=0; PASSED_TESTS=0; FAILED_TESTS=0; PASS_RATE=0; TEST_COVERAGE=85
          fi

          # Set status emoji and color
          if [ $PASS_RATE -ge 95 ]; then
            STATUS_EMOJI="🎯"; STATUS="EXCELLENT"
          elif [ $PASS_RATE -ge 85 ]; then
            STATUS_EMOJI="✅"; STATUS="GOOD"
          elif [ $PASS_RATE -ge 70 ]; then
            STATUS_EMOJI="⚠️"; STATUS="NEEDS ATTENTION"
          else
            STATUS_EMOJI="🚨"; STATUS="CRITICAL"
          fi

          # Generate enhanced summary
          echo "# $STATUS_EMOJI E2E Test Execution Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 📊 Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Overall Status** | $STATUS | $STATUS_EMOJI |" >> $GITHUB_STEP_SUMMARY
          echo "| **Total Test Cases** | $TOTAL_TEST_CASES | 📝 |" >> $GITHUB_STEP_SUMMARY
          echo "| **Test Files** | $TOTAL_TESTS | 📁 |" >> $GITHUB_STEP_SUMMARY
          echo "| **Passed** | $PASSED_TESTS | ✅ |" >> $GITHUB_STEP_SUMMARY
          echo "| **Failed** | $FAILED_TESTS | ❌ |" >> $GITHUB_STEP_SUMMARY
          echo "| **Pass Rate** | ${PASS_RATE}% | $([ $PASS_RATE -ge 85 ] && echo "✅" || echo "⚠️") |" >> $GITHUB_STEP_SUMMARY
          echo "| **Test Coverage** | ${TEST_COVERAGE}% | 📈 |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## ⚙️ Execution Configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment:** \`${{ github.event.inputs.environment || 'test' }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Scope:** \`${{ github.event.inputs.test_scope || 'smoke' }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Parallel Workers:** \`${{ github.event.inputs.workers || '3' }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger:** \`${{ github.event_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Run Number:** \`#${{ github.run_number }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Execution Time:** \`$(date '+%Y-%m-%d %H:%M:%S UTC')\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## 🔗 Quick Access" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- 📊 [View Pipeline](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- 📁 [Download Enhanced Reports](#artifacts)" >> $GITHUB_STEP_SUMMARY
          echo "- 💻 [Source Code](${{ github.server_url }}/${{ github.repository }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Add recommendation based on results
          echo "## 🎯 Recommendations" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ $PASS_RATE -ge 95 ]; then
            echo "✅ **Excellent quality!** System is ready for production deployment." >> $GITHUB_STEP_SUMMARY
            echo "- Continue monitoring for regression" >> $GITHUB_STEP_SUMMARY
            echo "- Consider expanding test coverage" >> $GITHUB_STEP_SUMMARY
          elif [ $PASS_RATE -ge 85 ]; then
            echo "⚠️ **Good quality with minor issues.** Review failed tests before deployment." >> $GITHUB_STEP_SUMMARY
            echo "- Investigate and fix failed test cases" >> $GITHUB_STEP_SUMMARY
            echo "- Review test environment setup" >> $GITHUB_STEP_SUMMARY
          elif [ $PASS_RATE -ge 70 ]; then
            echo "🔍 **Quality concerns detected.** Requires immediate attention before deployment." >> $GITHUB_STEP_SUMMARY
            echo "- Immediate investigation of failed tests required" >> $GITHUB_STEP_SUMMARY
            echo "- Review recent code changes" >> $GITHUB_STEP_SUMMARY
            echo "- Consider additional regression testing" >> $GITHUB_STEP_SUMMARY
          else
            echo "🚨 **Critical quality issues!** Deployment should be blocked until issues are resolved." >> $GITHUB_STEP_SUMMARY
            echo "- **BLOCK DEPLOYMENT** immediately" >> $GITHUB_STEP_SUMMARY
            echo "- Emergency team review required" >> $GITHUB_STEP_SUMMARY
            echo "- Full regression testing needed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📧 **Enhanced email report available in artifacts for detailed analysis**" >> $GITHUB_STEP_SUMMARY

      - name: Send Enhanced Email Report
        if: ${{ always() && github.event.inputs.email_recipients != '' }}
        run: |
          cd automationexercise-e2e-pom

          # Set environment variables for the script
          export ENVIRONMENT="${{ github.event.inputs.environment || 'test' }}"
          export TEST_SCOPE="${{ github.event.inputs.test_scope || 'smoke' }}"
          export WORKERS="${{ github.event.inputs.workers || '3' }}"
          export BROWSER="chromium"
          export TRIGGER="${{ github.event_name }}"
          export RUN_NUMBER="${{ github.run_number }}"
          export EXECUTION_TIME="$(date '+%Y-%m-%d %H:%M:%S UTC')"
          export GITHUB_SERVER_URL="${{ github.server_url }}"
          export GITHUB_REPOSITORY="${{ github.repository }}"
          export GITHUB_RUN_ID="${{ github.run_id }}"

          # Make script executable and run it
          chmod +x replace-email-variables.sh
          ./replace-email-variables.sh

      - name: Send Professional Email
        if: ${{ always() && github.event.inputs.email_recipients != '' }}
        run: |
          cd automationexercise-e2e-pom

          # Read the email content
          if [ -f "test-summary/final-email.html" ]; then
            EMAIL_CONTENT=$(cat test-summary/final-email.html)
            echo "Using professional email template"
          else
            EMAIL_CONTENT="<h2>E2E Test Report</h2><p>Tests completed. Please check artifacts for detailed results.</p>"
            echo "Using fallback email template"
          fi

          # Export email content to environment file for next step
          echo "EMAIL_HTML_BODY<<EOF" >> $GITHUB_ENV
          echo "$EMAIL_CONTENT" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      - name: Send Email with Content
        if: ${{ always() && github.event.inputs.email_recipients != '' }}
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          secure: false
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "E2E Test Report - ${{ github.event.inputs.environment || 'test' }} Environment - Run #${{ github.run_number }}"
          to: ${{ github.event.inputs.email_recipients }}
          from: "QA Automation <${{ secrets.EMAIL_USERNAME }}>"
          html_body: ${{ env.EMAIL_HTML_BODY }}

      - name: Send Teams Notification
        if: always()
        run: |
          cd automationexercise-e2e-pom

          # Read metrics if available
          if [ -f "test-summary/metrics.json" ]; then
            TOTAL_TESTS=$(grep '"total_test_cases"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            PASSED_TESTS=$(grep '"passed_tests"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            FAILED_TESTS=$(grep '"failed_tests"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            PASS_RATE=$(grep '"pass_rate"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
          else
            TOTAL_TESTS=0; PASSED_TESTS=0; FAILED_TESTS=0; PASS_RATE=0
          fi

          # Determine status
          if [ $PASS_RATE -ge 95 ]; then
            STATUS="EXCELLENT"
          elif [ $PASS_RATE -ge 85 ]; then
            STATUS="GOOD"
          else
            STATUS="CRITICAL"
          fi

          # Send notification using script
          export TEAMS_WEBHOOK_URL="${{ secrets.TEAMS_WEBHOOK_URL }}"

          PIPELINE_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          MESSAGE="E2E Test Report - Run #${{ github.run_number }} | Status: $STATUS | Environment: ${{ github.event.inputs.environment || 'test' }} | Scope: ${{ github.event.inputs.test_scope || 'smoke' }} | Tests: $TOTAL_TESTS | Passed: $PASSED_TESTS | Failed: $FAILED_TESTS | Pass Rate: ${PASS_RATE}% | Pipeline: $PIPELINE_URL"

          npm run teams:notify "$MESSAGE" || echo "Teams notification failed, continuing..."
        continue-on-error: true

      - name: Send Slack Notification
        if: always()
        run: |
          cd automationexercise-e2e-pom

          # Read metrics if available
          if [ -f "test-summary/metrics.json" ]; then
            TOTAL_TESTS=$(grep '"total_test_cases"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            PASSED_TESTS=$(grep '"passed_tests"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            FAILED_TESTS=$(grep '"failed_tests"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
            PASS_RATE=$(grep '"pass_rate"' test-summary/metrics.json | sed 's/.*: *\([0-9]*\).*/\1/' || echo "0")
          else
            TOTAL_TESTS=0; PASSED_TESTS=0; FAILED_TESTS=0; PASS_RATE=0
          fi

          # Determine status
          if [ $PASS_RATE -ge 95 ]; then
            STATUS="EXCELLENT"
          elif [ $PASS_RATE -ge 85 ]; then
            STATUS="GOOD"
          else
            STATUS="CRITICAL"
          fi

          # Send notification using script
          export SLACK_WEBHOOK_URL="${{ secrets.SLACK_WEBHOOK_URL }}"

          PIPELINE_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          MESSAGE="E2E Test Report - Run #${{ github.run_number }} | Status: $STATUS | Environment: ${{ github.event.inputs.environment || 'test' }} | Scope: ${{ github.event.inputs.test_scope || 'smoke' }} | Tests: $TOTAL_TESTS | Passed: $PASSED_TESTS | Failed: $FAILED_TESTS | Pass Rate: ${PASS_RATE}% | Pipeline: $PIPELINE_URL"

          npm run slack:notify "$MESSAGE" || echo "Slack notification failed, continuing..."
        continue-on-error: true

  # AI Analysis Job - Runs after tests complete
  ai-analysis:
    runs-on: ubuntu-latest
    needs: test
    if: always()
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download test artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          path: ./test-artifacts
          merge-multiple: true

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: ai-analysis/requirements-github.txt

      - name: Install AI Analysis Dependencies
        run: |
          cd ai-analysis
          pip install -r requirements-github.txt

      - name: Run AI Analysis with GitHub Copilot
        id: ai_analysis
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd ai-analysis
          
          # Check if test results exist
          if [ ! -d "../test-artifacts" ] || [ -z "$(ls -A ../test-artifacts 2>/dev/null)" ]; then
            echo "⚠️ No test results found, generating fallback analysis..."
            python analyze-github.py --fallback > analysis-output.json
          else
            echo "✅ Test results found, running AI analysis..."
            python analyze-github.py --test-results ../test-artifacts > analysis-output.json || \
              python analyze-github.py --fallback > analysis-output.json
          fi
          
          # Display analysis summary
          echo "## 🤖 AI Analysis Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "analysis-output.json" ]; then
            cat analysis-output.json >> $GITHUB_STEP_SUMMARY
            echo "✅ AI analysis completed successfully"
          else
            echo "❌ AI analysis failed to generate output"
            echo "{\"error\": \"No analysis output generated\"}" > analysis-output.json
          fi

      - name: Upload AI Analysis Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-analysis-report-${{ github.run_number }}
          path: ai-analysis/analysis-output.json
          retention-days: 30

      - name: Comment Analysis on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const analysisPath = 'ai-analysis/analysis-output.json';
            
            if (!fs.existsSync(analysisPath)) {
              console.log('No analysis file found');
              return;
            }
            
            const analysis = JSON.parse(fs.readFileSync(analysisPath, 'utf8'));
            
            const comment = `## 🤖 AI Test Analysis
            
            ${JSON.stringify(analysis, null, 2)}
            
            ---
            *Analysis powered by GitHub Copilot Models*
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

#!/usr/bin/env python3
"""
Convert metrics.json to Playwright JSON format for AI analysis.

This script converts the test metrics generated by the E2E test suite
into a format compatible with Playwright's JSON reporter, which is
expected by the AI analysis scripts.
"""

import json
import sys
from pathlib import Path
from datetime import datetime


def create_spec(test_info: dict, file_path: str) -> dict:
    """Create a spec (test case) from test info."""
    test_status = test_info.get('status', 'unknown').lower()
    error_info = test_info.get('error', '')
    
    return {
        "title": test_info.get('name', 'Test Case'),
        "ok": test_status == 'passed',
        "tests": [{
            "expectedStatus": "passed",
            "timeout": 30000,
            "annotations": [],
            "projectName": "chromium",
            "results": [{
                "workerIndex": 0,
                "status": test_status,
                "duration": test_info.get('duration', 0),
                "errors": [{"message": error_info}] if test_status == 'failed' and error_info else [],
                "stderr": [],
                "stdout": []
            }],
            "status": test_status
        }],
        "file": file_path,
        "line": 0,
        "column": 0
    }


def create_spec_from_detail(test_detail: dict, file_path: str) -> dict:
    """Create a spec from failed_test_details format."""
    error_msg = test_detail.get('error', 'Unknown error')
    
    return {
        "title": test_detail.get('name', 'Test Case'),
        "ok": False,
        "tests": [{
            "expectedStatus": "passed",
            "timeout": 30000,
            "annotations": [],
            "projectName": "chromium",
            "results": [{
                "workerIndex": 0,
                "status": "failed",
                "duration": test_detail.get('duration', 0),
                "errors": [{"message": error_msg}],
                "stderr": [],
                "stdout": []
            }],
            "status": "failed"
        }],
        "file": file_path,
        "line": 0,
        "column": 0
    }


def convert_metrics_to_playwright_format(metrics_path: str, output_path: str) -> None:
    """
    Convert metrics.json to Playwright JSON format.
    
    Args:
        metrics_path: Path to the metrics.json file
        output_path: Path to write the Playwright-compatible JSON
    """
    try:
        # Read metrics.json
        with open(metrics_path, 'r') as f:
            metrics = json.load(f)
        
        print(f"✅ Loaded metrics from: {metrics_path}")
        print(f"📊 Test counts - Total: {metrics.get('total_test_cases', 0)}, "
              f"Passed: {metrics.get('passed_tests', 0)}, "
              f"Failed: {metrics.get('failed_tests', 0)}")
        
        # Extract test information
        test_files = metrics.get('test_files', [])
        failed_test_details = metrics.get('failed_test_details', [])
        total_tests = metrics.get('total_test_cases', 0)
        passed_tests = metrics.get('passed_tests', 0)
        failed_tests = metrics.get('failed_tests', 0)
        skipped_tests = metrics.get('skipped_tests', 0)
        
        # Build Playwright-compatible JSON structure
        suites = []
        
        print(f"🔍 Data available:")
        print(f"   - test_files: {len(test_files)} files")
        print(f"   - failed_test_details: {len(failed_test_details)} failures")
        print(f"   - Total test cases: {total_tests}")
        
        # If we have test_files array, use it
        if test_files:
            print(f"📁 Processing {len(test_files)} test files...")
            for file_info in test_files:
                file_path = file_info.get('file', 'unknown')
                file_status = file_info.get('status', 'unknown')
                test_count = file_info.get('test_count', 1)
                duration = file_info.get('duration', 0)
                
                # Create suite structure
                suite = {
                    "title": Path(file_path).stem if file_path != 'unknown' else 'Unknown Test',
                    "file": file_path,
                    "column": 0,
                    "line": 0,
                    "specs": []
                }
                
                # Add spec (test case) information
                if 'tests' in file_info and file_info['tests']:
                    for test in file_info['tests']:
                        spec = create_spec(test, file_path)
                        suite['specs'].append(spec)
                else:
                    # Create placeholder spec based on file status
                    spec = {
                        "title": f"Tests in {Path(file_path).name}",
                        "ok": file_status.lower() == 'passed',
                        "tests": [{
                            "expectedStatus": "passed",
                            "timeout": 30000,
                            "annotations": [],
                            "projectName": "chromium",
                            "results": [{
                                "workerIndex": 0,
                                "status": file_status.lower(),
                                "duration": duration,
                                "errors": [],
                                "stderr": [],
                                "stdout": []
                            }],
                            "status": file_status.lower()
                        }],
                        "file": file_path,
                        "line": 0,
                        "column": 0
                    }
                    suite['specs'].append(spec)
                
                suites.append(suite)
        
        # If we only have failed_test_details, create suites from them
        elif failed_test_details:
            print(f"📝 Creating suites from {len(failed_test_details)} failed test details...")
            
            # Group tests by file
            tests_by_file = {}
            for test_detail in failed_test_details:
                file_path = test_detail.get('file', 'unknown')
                if file_path not in tests_by_file:
                    tests_by_file[file_path] = []
                tests_by_file[file_path].append(test_detail)
            
            # Create suites for failed tests
            for file_path, tests in tests_by_file.items():
                suite = {
                    "title": Path(file_path).stem if file_path != 'unknown' else 'Failed Tests',
                    "file": file_path,
                    "column": 0,
                    "line": 0,
                    "specs": []
                }
                
                for test_detail in tests:
                    spec = create_spec_from_detail(test_detail, file_path)
                    suite['specs'].append(spec)
                
                suites.append(suite)
            
            # Also create a suite for passed tests (aggregate)
            if passed_tests > 0:
                suite = {
                    "title": "Passed Tests",
                    "file": "tests/passed",
                    "column": 0,
                    "line": 0,
                    "specs": [{
                        "title": f"{passed_tests} tests passed",
                        "ok": True,
                        "tests": [{
                            "expectedStatus": "passed",
                            "timeout": 30000,
                            "annotations": [],
                            "projectName": "chromium",
                            "results": [{
                                "workerIndex": 0,
                                "status": "passed",
                                "duration": 0,
                                "errors": [],
                                "stderr": [],
                                "stdout": []
                            }],
                            "status": "passed"
                        }],
                        "file": "tests/passed",
                        "line": 0,
                        "column": 0
                    }]
                }
                suites.append(suite)
        
        # Fallback: if no test_files and no failed_test_details, create from stats
        else:
            print(f"⚠️  No test_files or failed_test_details found!")
            print(f"📊 Creating suites from stats only...")
            
            # Create aggregate suites based on pass/fail counts
            if failed_tests > 0:
                suite = {
                    "title": "Failed Tests",
                    "file": "tests/failed",
                    "column": 0,
                    "line": 0,
                    "specs": [{
                        "title": f"{failed_tests} test(s) failed",
                        "ok": False,
                        "tests": [{
                            "expectedStatus": "passed",
                            "timeout": 30000,
                            "annotations": [],
                            "projectName": "chromium",
                            "results": [{
                                "workerIndex": 0,
                                "status": "failed",
                                "duration": 0,
                                "errors": [{"message": "Test failed - details not available in metrics"}],
                                "stderr": [],
                                "stdout": []
                            }],
                            "status": "failed"
                        }],
                        "file": "tests/failed",
                        "line": 0,
                        "column": 0
                    }]
                }
                suites.append(suite)
            
            if passed_tests > 0:
                suite = {
                    "title": "Passed Tests",
                    "file": "tests/passed",
                    "column": 0,
                    "line": 0,
                    "specs": [{
                        "title": f"{passed_tests} test(s) passed",
                        "ok": True,
                        "tests": [{
                            "expectedStatus": "passed",
                            "timeout": 30000,
                            "annotations": [],
                            "projectName": "chromium",
                            "results": [{
                                "workerIndex": 0,
                                "status": "passed",
                                "duration": 0,
                                "errors": [],
                                "stderr": [],
                                "stdout": []
                            }],
                            "status": "passed"
                        }],
                        "file": "tests/passed",
                        "line": 0,
                        "column": 0
                    }]
                }
                suites.append(suite)
        
        # Build final output structure
        playwright_json = {
            "config": {
                "configFile": "playwright.config.ts",
                "rootDir": "/workspace/automationexercise-e2e-pom",
                "version": "1.40.0"
            },
            "suites": suites,
            "errors": [],
            "stats": {
                "startTime": metrics.get('execution_start_time', datetime.now().isoformat()),
                "duration": metrics.get('total_duration', 0) * 1000,  # Convert to ms
                "expected": passed_tests,
                "unexpected": failed_tests,
                "flaky": 0,
                "skipped": skipped_tests
            }
        }
        
        # Write output
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w') as f:
            json.dump(playwright_json, f, indent=2)
        
        print(f"✅ Converted to Playwright format: {output_path}")
        print(f"📁 Created {len(suites)} test suites")
        
    except FileNotFoundError:
        print(f"❌ Error: metrics.json not found at {metrics_path}")
        # Create minimal valid output
        create_minimal_playwright_json(output_path)
        sys.exit(1)
        
    except json.JSONDecodeError as e:
        print(f"❌ Error: Invalid JSON in metrics.json: {e}")
        create_minimal_playwright_json(output_path)
        sys.exit(1)
        
    except Exception as e:
        print(f"❌ Error converting metrics: {e}")
        import traceback
        traceback.print_exc()
        create_minimal_playwright_json(output_path)
        sys.exit(1)


def create_minimal_playwright_json(output_path: str) -> None:
    """Create a minimal valid Playwright JSON file."""
    minimal_json = {
        "config": {
            "configFile": "playwright.config.ts",
            "rootDir": "/workspace/automationexercise-e2e-pom",
            "version": "1.40.0"
        },
        "suites": [],
        "errors": [],
        "stats": {
            "startTime": datetime.now().isoformat(),
            "duration": 0,
            "expected": 0,
            "unexpected": 0,
            "flaky": 0,
            "skipped": 0
        }
    }
    
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w') as f:
        json.dump(minimal_json, f, indent=2)
    
    print(f"⚠️  Created minimal placeholder JSON at {output_path}")


def main():
    """Main entry point."""
    if len(sys.argv) < 3:
        print("Usage: python3 convert-metrics.py <input_metrics.json> <output_playwright.json>")
        sys.exit(1)
    
    metrics_path = sys.argv[1]
    output_path = sys.argv[2]
    
    print(f"🔄 Converting metrics to Playwright format...")
    print(f"📥 Input: {metrics_path}")
    print(f"📤 Output: {output_path}")
    
    convert_metrics_to_playwright_format(metrics_path, output_path)


if __name__ == '__main__':
    main()
